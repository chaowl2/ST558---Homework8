[
  {
    "objectID": "hw8.html",
    "href": "hw8.html",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "",
    "text": "This analysis builds several linear regression models to predict daily bike rentals in Seoul from weather and seasonal factors. I (1) clean and aggregate the hourly data to the day level, (2) create a weekend/weekday indicator, (3) compare three modeling “recipes” via 10-fold cross-validation, and (4) evaluate the best model on a held-out test set. I prioritize RMSE as the selection metric because it measures average prediction error on the outcome’s natural scale (bike count).\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tailor       0.1.0 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ recipes      1.3.1      ✔ yardstick    1.3.2 \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(broom)"
  },
  {
    "objectID": "hw8.html#reading-data",
    "href": "hw8.html#reading-data",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Reading Data",
    "text": "Reading Data\n\n# read in the data\nurl <- \"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\"\nbikes_raw <- readr::read_csv(url, show_col_types = FALSE)"
  },
  {
    "objectID": "hw8.html#eda",
    "href": "hw8.html#eda",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "hw8.html#data-and-initial-checks",
    "href": "hw8.html#data-and-initial-checks",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Data and initial checks",
    "text": "Data and initial checks\nI load the provided Seoul Bike Sharing dataset and convert key variables to appropriate types. I then examine missingness and factor levels to confirm they match expectations.\nKey notes from cleaning:\n\ndate is parsed to Date; seasons, holiday, and functioning_day are factors.\n\nThe assignment hints that Functioning Day has a single dominant level; I restrict the analysis to functioning days and then aggregate hourly rows to daily by summing bike counts, rainfall, and snowfall, and averaging the other weather variables. This yields one record per day suitable for daily-level modeling.\n\n\n# inspect types/missingness\nbikes <- bikes_raw %>%\n  clean_names()\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 4 is invalid UTF-8\n\n\nWarning in grepl(x = string, pattern = current_unicode, fixed = TRUE): input\nstring 8 is invalid UTF-8\n\nglimpse(bikes)\n\nRows: 8,760\nColumns: 14\n$ date                    <chr> \"01/12/2017\", \"01/12/2017\", \"01/12/2017\", \"01/…\n$ rented_bike_count       <dbl> 254, 204, 173, 107, 78, 100, 181, 460, 930, 49…\n$ hour                    <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, …\n$ temperature_c           <dbl> -5.2, -5.5, -6.0, -6.2, -6.0, -6.4, -6.6, -7.4…\n$ humidity_percent        <dbl> 37, 38, 39, 40, 36, 37, 35, 38, 37, 27, 24, 21…\n$ wind_speed_m_s          <dbl> 2.2, 0.8, 1.0, 0.9, 2.3, 1.5, 1.3, 0.9, 1.1, 0…\n$ visibility_10m          <dbl> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000…\n$ dew_point_temperature_c <dbl> -17.6, -17.6, -17.7, -17.6, -18.6, -18.7, -19.…\n$ solar_radiation_mj_m2   <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00…\n$ rainfall_mm             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ snowfall_cm             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ seasons                 <chr> \"Winter\", \"Winter\", \"Winter\", \"Winter\", \"Winte…\n$ holiday                 <chr> \"No Holiday\", \"No Holiday\", \"No Holiday\", \"No …\n$ functioning_day         <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes…\n\nsapply(bikes, function(x) sum(is.na(x)))  # missingness counts\n\n                   date       rented_bike_count                    hour \n                      0                       0                       0 \n          temperature_c        humidity_percent          wind_speed_m_s \n                      0                       0                       0 \n         visibility_10m dew_point_temperature_c   solar_radiation_mj_m2 \n                      0                       0                       0 \n            rainfall_mm             snowfall_cm                 seasons \n                      0                       0                       0 \n                holiday         functioning_day \n                      0                       0 \n\n# Convert date; make factors for categorical vars per spec\n# Original columns (after clean_names): date, seasons, holiday, functioning_day\nbikes <- bikes %>%\n  mutate(\n    date = dmy(date),\n    seasons = factor(seasons),\n    holiday = factor(holiday),\n    functioning_day = factor(functioning_day)\n  )\n\n# Numeric summaries & categorical levels\nbikes %>%\n  summarise(across(where(is.numeric), list(min = min, mean = mean, sd = sd, max = max)))\n\n# A tibble: 1 × 40\n  rented_bike_count_min rented_bike_count_mean rented_bike_count_sd\n                  <dbl>                  <dbl>                <dbl>\n1                     0                   705.                 645.\n# ℹ 37 more variables: rented_bike_count_max <dbl>, hour_min <dbl>,\n#   hour_mean <dbl>, hour_sd <dbl>, hour_max <dbl>, temperature_c_min <dbl>,\n#   temperature_c_mean <dbl>, temperature_c_sd <dbl>, temperature_c_max <dbl>,\n#   humidity_percent_min <dbl>, humidity_percent_mean <dbl>,\n#   humidity_percent_sd <dbl>, humidity_percent_max <dbl>,\n#   wind_speed_m_s_min <dbl>, wind_speed_m_s_mean <dbl>,\n#   wind_speed_m_s_sd <dbl>, wind_speed_m_s_max <dbl>, …\n\nmap(\n  bikes %>% select(where(is.factor)),\n  ~ tibble(levels = levels(.x))\n)\n\n$seasons\n# A tibble: 4 × 1\n  levels\n  <chr> \n1 Autumn\n2 Spring\n3 Summer\n4 Winter\n\n$holiday\n# A tibble: 2 × 1\n  levels    \n  <chr>     \n1 Holiday   \n2 No Holiday\n\n$functioning_day\n# A tibble: 2 × 1\n  levels\n  <chr> \n1 No    \n2 Yes   \n\n# Check distribution and (likely) subset to functional hours only.\nbikes %>% count(functioning_day)\n\n# A tibble: 2 × 2\n  functioning_day     n\n  <fct>           <int>\n1 No                295\n2 Yes              8465\n\nbikes_fun <- bikes %>% filter(functioning_day == \"Yes\" | functioning_day == \"Fun\" | functioning_day == \"Functional\") %>% \n  identity()\n\n\n# summarize stats\n\ndaily <- bikes_fun %>%\n  group_by(date, seasons, holiday) %>%\n  summarise(\n    bike_count = sum(rented_bike_count, na.rm = TRUE),\n    rainfall = sum(rainfall_mm, na.rm = TRUE),\n    snowfall = sum(snowfall_cm, na.rm = TRUE),\n    temperature = mean(temperature_c, na.rm = TRUE),\n    humidity = mean(humidity_percent, na.rm = TRUE),\n    windspeed = mean(wind_speed_m_s, na.rm = TRUE),\n    visibility = mean(visibility_10m, na.rm = TRUE),\n    dew_point = mean(dew_point_temperature_c, na.rm = TRUE),\n    solar_rad = mean(solar_radiation_mj_m2, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Re-check summaries/correlations on daily data\nsummary(daily)\n\n      date              seasons         holiday      bike_count   \n Min.   :2017-12-01   Autumn:81   Holiday   : 17   Min.   :  977  \n 1st Qu.:2018-02-27   Spring:90   No Holiday:336   1st Qu.: 6967  \n Median :2018-05-28   Summer:92                    Median :18563  \n Mean   :2018-05-28   Winter:90                    Mean   :17485  \n 3rd Qu.:2018-08-24                                3rd Qu.:26285  \n Max.   :2018-11-30                                Max.   :36149  \n    rainfall         snowfall       temperature         humidity    \n Min.   : 0.000   Min.   : 0.000   Min.   :-14.738   Min.   :22.25  \n 1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.:  3.304   1st Qu.:47.58  \n Median : 0.000   Median : 0.000   Median : 13.738   Median :57.17  \n Mean   : 3.576   Mean   : 1.863   Mean   : 12.776   Mean   :58.17  \n 3rd Qu.: 0.500   3rd Qu.: 0.000   3rd Qu.: 22.592   3rd Qu.:67.71  \n Max.   :95.500   Max.   :78.700   Max.   : 33.742   Max.   :95.88  \n   windspeed        visibility       dew_point         solar_rad      \n Min.   :0.6625   Min.   : 214.3   Min.   :-27.750   Min.   :0.02917  \n 1st Qu.:1.3042   1st Qu.:1087.0   1st Qu.: -5.188   1st Qu.:0.28333  \n Median :1.6583   Median :1557.8   Median :  4.612   Median :0.56500  \n Mean   :1.7261   Mean   :1434.0   Mean   :  3.954   Mean   :0.56773  \n 3rd Qu.:1.9542   3rd Qu.:1874.3   3rd Qu.: 14.921   3rd Qu.:0.82000  \n Max.   :4.0000   Max.   :2000.0   Max.   : 25.038   Max.   :1.21667  \n\ndaily %>% select(where(is.numeric)) %>% cor(use = \"pairwise.complete.obs\")\n\n             bike_count    rainfall    snowfall  temperature    humidity\nbike_count   1.00000000 -0.23910905 -0.26529110  0.753076732  0.03588697\nrainfall    -0.23910905  1.00000000 -0.02313404  0.144517274  0.52864263\nsnowfall    -0.26529110 -0.02313404  1.00000000 -0.266963662  0.06539191\ntemperature  0.75307673  0.14451727 -0.26696366  1.000000000  0.40416749\nhumidity     0.03588697  0.52864263  0.06539191  0.404167486  1.00000000\nwindspeed   -0.19288142 -0.10167578  0.02088156 -0.260721792 -0.23425778\nvisibility   0.16599375 -0.22199387 -0.10188902  0.002336683 -0.55917733\ndew_point    0.65047655  0.26456621 -0.20955286  0.962796255  0.63204729\nsolar_rad    0.73589290 -0.32270413 -0.23343056  0.550274301 -0.27444967\n              windspeed   visibility  dew_point   solar_rad\nbike_count  -0.19288142  0.165993749  0.6504765  0.73589290\nrainfall    -0.10167578 -0.221993866  0.2645662 -0.32270413\nsnowfall     0.02088156 -0.101889019 -0.2095529 -0.23343056\ntemperature -0.26072179  0.002336683  0.9627963  0.55027430\nhumidity    -0.23425778 -0.559177334  0.6320473 -0.27444967\nwindspeed    1.00000000  0.206022636 -0.2877032  0.09612635\nvisibility   0.20602264  1.000000000 -0.1535516  0.27139591\ndew_point   -0.28770322 -0.153551591  1.0000000  0.38315713\nsolar_rad    0.09612635  0.271395906  0.3831571  1.00000000\n\n# A couple of quick plots (optional, expand as you like)\nggplot(daily, aes(temperature, bike_count, color = seasons)) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Bike Count vs Temperature by Season\")\n\n\n\nggplot(daily, aes(rainfall, bike_count)) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Bike Count vs Rainfall\")"
  },
  {
    "objectID": "hw8.html#traintest-split-and-resampling",
    "href": "hw8.html#traintest-split-and-resampling",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Train/test split and resampling",
    "text": "Train/test split and resampling\nTo evaluate out-of-sample performance, I create a 75/25 train–test split of the daily dataset. I stratify by seasons so the proportion of seasons is similar in both sets. I fix the seed for reproducibility. On the training data, I set up 10-fold cross-validation (also stratified by season) to compare model variants fairly while using most of the data for fitting on each fold. This gives stable RMSE estimates and reduces variance from any single split.\n\n# Train/Test split (75/25) stratified by season\n\nset.seed(2025)\nsplit <- initial_split(daily, prop = 0.75, strata = seasons)\ntrain <- training(split)\ntest  <- testing(split)\n\nset.seed(2025)\nfolds <- vfold_cv(train, v = 10, strata = seasons)"
  },
  {
    "objectID": "hw8.html#feature-engineering",
    "href": "hw8.html#feature-engineering",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Feature engineering",
    "text": "Feature engineering\nI add a day_type indicator (Weekend vs Weekday) using the calendar date to capture systematic demand differences by day of week."
  },
  {
    "objectID": "hw8.html#modeling-strategy",
    "href": "hw8.html#modeling-strategy",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Modeling strategy",
    "text": "Modeling strategy\nI compare three linear-model “recipes” that share the same base predictors (season, holiday, day_type, and daily weather features):\n\nRecipe 1 (Baseline): Dummy-code categoricals and standardize numeric predictors.\nRecipe 2 (Interactions): Baseline + interactions to capture heterogeneous seasonal effects and the joint effect of temperature with rainfall.\nRecipe 3 (Quadratic): Recipe 2 + quadratic terms for numeric predictors with enough unique values (to avoid overfitting/degenerate polynomials).\n\nUsing ordinary least squares lets me interpret coefficients while keeping the pipeline simple and fast to cross-validate.\n\n# 1) Add day_type to the split data\ntrain <- train %>%\n  mutate(day_type = factor(if_else(wday(date, week_start = 1) >= 6, \"Weekend\", \"Weekday\")))\ntest  <- test %>%\n  mutate(day_type = factor(if_else(wday(date, week_start = 1) >= 6, \"Weekend\", \"Weekday\")))\n\n# Safety check\nstopifnot(\"day_type\" %in% names(train))\n\n# 2) Recreate folds AFTER day_type exists in train\nset.seed(2025)\nfolds <- vfold_cv(train, v = 10, strata = seasons)\n\n# 3) Base formula used by all recipes\nbase_formula <- bike_count ~ seasons + holiday + day_type +\n  temperature + humidity + windspeed + visibility + dew_point + solar_rad + rainfall + snowfall\n\n# 4) Recipes (build them now, with train that already has day_type)\n# Recipe 1: baseline (dummy + scale)\nrec1 <- recipe(base_formula, data = train) %>%\n  step_zv(all_predictors()) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_normalize(all_numeric_predictors())\n\n# Recipe 2: + interactions\n# NOTE: use starts_with(\"holiday_\") because holiday is dummy-coded\nrec2 <- recipe(base_formula, data = train) %>%\n  step_zv(all_predictors()) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_interact(~ starts_with(\"seasons_\"):starts_with(\"holiday_\")\n                 + starts_with(\"seasons_\"):temperature\n                 + temperature:rainfall) %>%\n  step_lincomb(all_predictors()) %>%\n  step_corr(all_numeric_predictors(), threshold = 0.999) %>%\n  step_normalize(all_numeric_predictors())\n\n# Compute which numeric predictors have >= 3 unique values (in TRAIN)\nnum_ok <- train %>%\n  dplyr::select(where(is.numeric), -bike_count) %>%\n  purrr::keep(~ dplyr::n_distinct(.x) >= 3) %>%\n  names()\n\n# Recipe 3: interactions + quadratic terms only for \"ok\" numerics\nrec3 <- recipe(base_formula, data = train) %>%\n  step_zv(all_predictors()) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_interact(~ starts_with(\"seasons_\"):starts_with(\"holiday_\")\n                 + starts_with(\"seasons_\"):temperature\n                 + temperature:rainfall) %>%\n  step_poly(any_of(num_ok), degree = 2) %>%\n  step_lincomb(all_predictors()) %>%\n  step_corr(all_numeric_predictors(), threshold = 0.999) %>%\n  step_normalize(all_numeric_predictors())"
  },
  {
    "objectID": "hw8.html#model-specification-and-workflows",
    "href": "hw8.html#model-specification-and-workflows",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Model specification and workflows",
    "text": "Model specification and workflows\nFor modeling, I use a linear regression specification implemented with the \"lm\" engine in tidymodels.\nI then create three separate workflows, each combining the same model type with a different data-preprocessing recipe defined earlier.\n\nWorkflow 1 (wf1) uses the baseline recipe with standardized numeric features and dummy-coded categoricals.\n\nWorkflow 2 (wf2) uses the recipe that adds selected interaction terms to capture relationships such as season × temperature and temperature × rainfall.\n\nWorkflow 3 (wf3) combines the interaction recipe with quadratic (squared) numeric terms to allow mild non-linearity.\n\nUsing workflows ensures that each recipe’s preprocessing steps are automatically applied during both training and evaluation, keeping the modeling process reproducible and consistent across all three variants.\n\n# Model spec & workflows\n\nlm_spec <- linear_reg() %>% set_engine(\"lm\")\n\nwf1 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec1)\nwf2 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec2)\nwf3 <- workflow() %>% add_model(lm_spec) %>% add_recipe(rec3)"
  },
  {
    "objectID": "hw8.html#cross-validation-results",
    "href": "hw8.html#cross-validation-results",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Cross-validation results",
    "text": "Cross-validation results\nI evaluate each recipe with 10-fold CV and select the model with the lowest mean RMSE.\n\n# 10-fold CV on training\n\nset.seed(2025)\nres1 <- fit_resamples(wf1, folds, metrics = metric_set(rmse, rsq), control = control_resamples(save_pred = TRUE))\nres2 <- fit_resamples(wf2, folds, metrics = metric_set(rmse, rsq), control = control_resamples(save_pred = TRUE))\nres3 <- fit_resamples(wf3, folds, metrics = metric_set(rmse, rsq), control = control_resamples(save_pred = TRUE))\n\ncollect_metrics(res1)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  <chr>   <chr>         <dbl> <int>    <dbl> <chr>          \n1 rmse    standard   4121.       10 188.     pre0_mod0_post0\n2 rsq     standard      0.829    10   0.0154 pre0_mod0_post0\n\ncollect_metrics(res2)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  <chr>   <chr>         <dbl> <int>    <dbl> <chr>          \n1 rmse    standard   3035.       10 226.     pre0_mod0_post0\n2 rsq     standard      0.906    10   0.0129 pre0_mod0_post0\n\ncollect_metrics(res3)\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config        \n  <chr>   <chr>         <dbl> <int>    <dbl> <chr>          \n1 rmse    standard   2820.       10 244.     pre0_mod0_post0\n2 rsq     standard      0.917    10   0.0147 pre0_mod0_post0\n\n# Compare mean RMSE across the three and pick best\nrmse_summary <- bind_rows(\n  collect_metrics(res1) %>% filter(.metric == \"rmse\") %>% mutate(model = \"rec1\"),\n  collect_metrics(res2) %>% filter(.metric == \"rmse\") %>% mutate(model = \"rec2\"),\n  collect_metrics(res3) %>% filter(.metric == \"rmse\") %>% mutate(model = \"rec3\")\n) %>%\n  arrange(mean)\n\nrmse_summary\n\n# A tibble: 3 × 7\n  .metric .estimator  mean     n std_err .config         model\n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>           <chr>\n1 rmse    standard   2820.    10    244. pre0_mod0_post0 rec3 \n2 rmse    standard   3035.    10    226. pre0_mod0_post0 rec2 \n3 rmse    standard   4121.    10    188. pre0_mod0_post0 rec1 \n\nbest_model <- rmse_summary$model[1]\nbest_wf <- switch(best_model, rec1 = wf1, rec2 = wf2, rec3 = wf3)\nbest_model\n\n[1] \"rec3\"\n\n\nrecipe 3 is the best model"
  },
  {
    "objectID": "hw8.html#final-model-evaluation-on-the-test-set",
    "href": "hw8.html#final-model-evaluation-on-the-test-set",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Final model evaluation on the test set",
    "text": "Final model evaluation on the test set\nAfter identifying the best-performing workflow from cross-validation, I refit that model on the entire training set and then evaluate it on the held-out 25% test set using last_fit().\nBecause the test data must include all predictors used in the model, I first confirm that the day_type feature (Weekend vs. Weekday) is present in the full dataset before recreating the stratified train/test split.\nlast_fit() automatically refits the chosen workflow (best_wf) on the training portion of split2 and computes performance metrics on the test portion.\nThe resulting output reports the test RMSE and R², which summarize how well the selected model generalizes to unseen data.\nA smaller RMSE indicates more accurate predictions of daily bike rental counts, while a higher R² shows that the model explains more of the variability in rental demand.\n\n# Final fit on full training; evaluate on test (last_fit)\n\ndaily <- daily %>%\n  mutate(day_type = factor(if_else(wday(date, week_start = 1) >= 6,\n                                   \"Weekend\", \"Weekday\")))\nsplit2 <- initial_split(daily, prop = 0.75, strata = seasons)\n\nfinal_fit <- last_fit(best_wf, split2)\n\n# Test metrics (includes RMSE on test set)\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  <chr>   <chr>          <dbl> <chr>          \n1 rmse    standard    3392.    pre0_mod0_post0\n2 rsq     standard       0.890 pre0_mod0_post0"
  },
  {
    "objectID": "hw8.html#coefficient-interpretation",
    "href": "hw8.html#coefficient-interpretation",
    "title": "HW8 – Basic Modeling Practice (Seoul Bike Sharing)",
    "section": "Coefficient interpretation",
    "text": "Coefficient interpretation\nTo better understand the drivers of bike rental demand, I extract and inspect the regression coefficients from the final fitted model.\nThe table below lists each term along with its estimated effect size, standard error, and test statistic, sorted by the absolute magnitude of the estimates.\nThis highlights which predictors have the strongest influence on daily rental counts.\nSeveral patterns:\n\nThe intercept represents the baseline expected rental count under the reference levels of categorical variables and average standardized numeric predictors.\n\nTemperature-related terms (including temperature_poly_1 and interactions like seasons_Summer_x_temperature) have large coefficients, confirming that warmer weather substantially increases demand—especially in summer.\n\nSeason indicators (seasons_Summer, seasons_Spring) capture shifts in baseline usage across the year, with summer showing strong positive effects.\n\nRainfall and snowfall–related interactions (e.g., temperature_x_rainfall) generally have negative coefficients.\n\nPolynomial terms (_poly_1) correspond to standardized numeric variables included with quadratic features.\n\nOverall, the signs and magnitudes of these coefficients are consistent with intuition:\nwarmer, sunnier days drive higher rental volumes, while colder or wetter conditions reduce usage.\n\n# Coefficient table from final model\n\nfinal_wflow <- extract_workflow(final_fit)\nfinal_fit_parsnip <- extract_fit_parsnip(final_wflow)\ncoef_table <- tidy(final_fit_parsnip) %>% arrange(desc(abs(estimate)))\ncoef_table %>% print(n = 30)\n\n# A tibble: 29 × 5\n   term                                 estimate std.error statistic   p.value\n   <chr>                                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)                          17435.        163.  107.     6.27e-201\n 2 seasons_Summer                       15059.       2334.    6.45   6.25e- 10\n 3 seasons_Summer_x_temperature        -13926.       2235.   -6.23   2.13e-  9\n 4 dew_point_poly_1                      8873.       4765.    1.86   6.38e-  2\n 5 seasons_Spring_x_holiday_No.Holiday  -4061.       1227.   -3.31   1.08e-  3\n 6 humidity_poly_1                      -3136.       1400.   -2.24   2.60e-  2\n 7 temperature_poly_2                   -2804.       1045.   -2.68   7.82e-  3\n 8 temperature_x_rainfall               -2776.        943.   -2.94   3.56e-  3\n 9 solar_rad_poly_1                      2736.        334.    8.20   1.63e- 14\n10 seasons_Winter_x_holiday_No.Holiday  -2571.        984.   -2.61   9.52e-  3\n11 seasons_Summer_x_holiday_No.Holiday  -2257.       1475.   -1.53   1.27e-  1\n12 seasons_Spring_x_temperature          2082.        560.    3.72   2.52e-  4\n13 seasons_Winter_x_temperature         -1858.        632.   -2.94   3.63e-  3\n14 holiday_No.Holiday                    1703.        373.    4.56   8.25e-  6\n15 rainfall_poly_2                       1069.        204.    5.24   3.59e-  7\n16 day_type_Weekend                     -1006.        171.   -5.89   1.33e-  8\n17 dew_point_poly_2                       688.        727.    0.947  3.45e-  1\n18 seasons_Winter                         595.       1181.    0.504  6.15e-  1\n19 temperature_poly_1                    -582.       4102.   -0.142  8.87e-  1\n20 humidity_poly_2                       -508.        343.   -1.48   1.41e-  1\n21 seasons_Spring                         453.       1359.    0.333  7.39e-  1\n22 windspeed_poly_1                      -423.        197.   -2.15   3.29e-  2\n23 rainfall_poly_1                       -267.        981.   -0.272  7.86e-  1\n24 visibility_poly_1                      247.        246.    1.01   3.15e-  1\n25 solar_rad_poly_2                      -173.        202.   -0.856  3.93e-  1\n26 snowfall_poly_2                       -163.        182.   -0.897  3.71e-  1\n27 windspeed_poly_2                       104.        181.    0.574  5.67e-  1\n28 visibility_poly_2                      -64.2       176.   -0.365  7.16e-  1\n29 snowfall_poly_1                          9.25      200.    0.0462 9.63e-  1"
  }
]